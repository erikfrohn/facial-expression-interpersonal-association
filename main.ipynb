{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main working file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "## system\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "## data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Rewrapping: \n",
    "\n",
    "\n",
    "NOT IMPLEMENTED - NEED TO ASK JULIETTE / IVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "data-in\\05_06\\VideoAudio\\pp05_navigator_reconstructed_video_and_audio_discussion_phase_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\05_06\\VideoAudio\\pp05_navigator_reconstructed_video_and_audio_discussion_phase_1.mp4\n",
      "Video already has metadata\n",
      "data-in\\05_06\\VideoAudio\\pp05_navigator_reconstructed_video_and_audio_instructional_video_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\05_06\\VideoAudio\\pp06_pilot_reconstructed_video_and_audio_discussion_phase_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\05_06\\VideoAudio\\pp06_pilot_reconstructed_video_and_audio_discussion_phase_1.mp4\n",
      "Video already has metadata\n",
      "data-in\\05_06\\VideoAudio\\pp06_pilot_reconstructed_video_and_audio_instructional_video_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\05_06\\VideoAudio\\test.mp4\n",
      "Video already has metadata\n",
      "data-in\\07_08\\VideoAudio\\pp07_navigator_reconstructed_video_and_audio_discussion_phase_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\07_08\\VideoAudio\\pp07_navigator_reconstructed_video_and_audio_discussion_phase_1.mp4\n",
      "Video already has metadata\n",
      "data-in\\07_08\\VideoAudio\\pp07_navigator_reconstructed_video_and_audio_instructional_video_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\07_08\\VideoAudio\\pp08_pilot_reconstructed_video_and_audio_discussion_phase_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\07_08\\VideoAudio\\pp08_pilot_reconstructed_video_and_audio_discussion_phase_1.mp4\n",
      "Video already has metadata\n",
      "data-in\\07_08\\VideoAudio\\pp08_pilot_reconstructed_video_and_audio_instructional_video_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\09_10\\VideoAudio\\pp09_navigator_reconstructed_video_and_audio_discussion_phase_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\09_10\\VideoAudio\\pp09_navigator_reconstructed_video_and_audio_discussion_phase_1.mp4\n",
      "Video already has metadata\n",
      "data-in\\09_10\\VideoAudio\\pp09_navigator_reconstructed_video_and_audio_instructional_video_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\09_10\\VideoAudio\\pp10_pilot_reconstructed_video_and_audio_discussion_phase_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\09_10\\VideoAudio\\pp10_pilot_reconstructed_video_and_audio_discussion_phase_1.mp4\n",
      "Video already has metadata\n",
      "data-in\\09_10\\VideoAudio\\pp10_pilot_reconstructed_video_and_audio_instructional_video_0.mp4\n",
      "Video already has metadata\n"
     ]
    }
   ],
   "source": [
    "# Import the function\n",
    "from util.video_transformation import rewrap_video\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "path_source = r\"data-in\"\n",
    "path_output =    r\"data-in\"\n",
    "\n",
    "for team_folder in os.listdir(path_source):\n",
    "    path_videos = os.path.join(path_source, team_folder, \"VideoAudio\")\n",
    "    files = glob.glob(os.path.join(path_videos, \"*.mp4\"))\n",
    "\n",
    "    for file in files:\n",
    "        rewrap_video(file, path_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of Action Units (AUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pp05_navigator_instructional_video_0.csv has already been processed. Continuing...\n",
      "pp05_navigator_discussion_phase_0.csv has already been processed. Continuing...\n",
      "pp05_navigator_discussion_phase_1.csv has already been processed. Continuing...\n",
      "pp06_pilot_instructional_video_0.csv has already been processed. Continuing...\n",
      "pp06_pilot_discussion_phase_0.csv has already been processed. Continuing...\n",
      "pp06_pilot_discussion_phase_1.csv has already been processed. Continuing...\n",
      "pp07_navigator_instructional_video_0.csv has already been processed. Continuing...\n",
      "pp07_navigator_discussion_phase_0.csv has already been processed. Continuing...\n",
      "pp07_navigator_discussion_phase_1.csv has already been processed. Continuing...\n",
      "pp08_pilot_instructional_video_0.csv has already been processed. Continuing...\n",
      "pp08_pilot_discussion_phase_0.csv has already been processed. Continuing...\n",
      "pp08_pilot_discussion_phase_1.csv has already been processed. Continuing...\n",
      "pp09_navigator_instructional_video_0.csv has already been processed. Continuing...\n",
      "pp09_navigator_discussion_phase_0.csv has already been processed. Continuing...\n",
      "pp09_navigator_discussion_phase_1.csv has already been processed. Continuing...\n",
      "pp10_pilot_instructional_video_0.csv has already been processed. Continuing...\n",
      "pp10_pilot_discussion_phase_0.csv has already been processed. Continuing...\n",
      "pp10_pilot_discussion_phase_1.csv has already been processed. Continuing...\n"
     ]
    }
   ],
   "source": [
    "from util.feature_extraction import extract_features\n",
    "data_in = r'data-in'\n",
    "data_out = r'data-out'\n",
    "\n",
    "for pair in os.listdir(data_in):\n",
    "    input_folder = os.path.join(data_in, pair)\n",
    "    output_folder = os.path.join(data_out, pair, 'au')\n",
    "    for participant in pair.split('_'):\n",
    "        # TODO: handle missing data (NaN or recovered)\n",
    "        aus = extract_features(input_folder, participant, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = r\"data-out\" \n",
    "for pair in os.listdir(location):\n",
    "    filename = os.path.join(location, pair, \"selection\")\n",
    "    os.makedirs(filename, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.feature_selection as fs\n",
    "location = r\"data-out\" \n",
    "names = ['discussion_phase_0', 'discussion_phase_1', 'instructional_video_0']\n",
    "for pair in os.listdir(location):\n",
    "    # TODO: make it check which pair the file is from and make two dataframes of that. Then combine\n",
    "    for file in os.listdir(os.path.join(location, pair, \"au\")):\n",
    "        if \".csv\" in file: \n",
    "            filename = os.path.join(location, pair, \"au\", file)\n",
    "            p, _ = file.split(\"_\",1)\n",
    "            df = pd.read_csv(filename)\n",
    "            for name in names:\n",
    "                if name in file:\n",
    "                    factors = fs.au_to_factors(df)\n",
    "                    factors.to_csv(os.path.join(location, pair, \"selection\", f\"{p}_{name}_factors.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files of pairs in data-out\\05_06 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "(17, 17)\n",
      "files of pairs in data-out\\07_08 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "(17, 17)\n",
      "(17, 17)\n",
      "(9000,)\n",
      "(9000,)\n",
      "(18889,)\n",
      "(9001,)\n",
      "(9000,)\n",
      "(18889,)\n",
      "(8997,)\n",
      "(8997,)\n",
      "(18888,)\n",
      "(9003,)\n",
      "(9001,)\n",
      "(18889,)\n",
      "(9000,)\n",
      "(9001,)\n",
      "(18889,)\n",
      "(9000,)\n",
      "(9001,)\n",
      "(18889,)\n"
     ]
    }
   ],
   "source": [
    "import util.feature_selection as fs\n",
    "\n",
    "# corrCA takes a df as input. This df should be all files for a pair. \n",
    "location = r\"data-out\" \n",
    "for pair in os.listdir(location):\n",
    "    filename = os.path.join(location, pair)\n",
    "    data = {}\n",
    "    nav, pil = pair.split(\"_\")\n",
    "    nav_df = pd.DataFrame()\n",
    "    pil_df = pd.DataFrame()\n",
    "    for file in os.listdir(os.path.join(filename, \"au\")):\n",
    "        if \".csv\" in file: \n",
    "            df = pd.read_csv(os.path.join(filename, \"au\", file))\n",
    "            if \".csv\" in file and nav in file:\n",
    "                nav_df = pd.concat([nav_df, df])\n",
    "            if \".csv\" in file and pil in file:\n",
    "                pil_df = pd.concat([pil_df, df])\n",
    "    fs.corrCA_weights(filename, nav_df, pil_df) #output = pair/corrca.csv\n",
    "\n",
    "names = ['discussion_phase_0', 'discussion_phase_1', 'instructional_video_0']\n",
    "for pair in os.listdir(location):\n",
    "    # TODO: make it check which pair the file is from and make two dataframes of that. Then combine\n",
    "    for file in os.listdir(os.path.join(location, pair, \"au\")):\n",
    "        if \".csv\" in file: \n",
    "            filename = os.path.join(location, pair, \"au\", file)\n",
    "            p, _ = file.split(\"_\", 1)\n",
    "            df = pd.read_csv(filename)\n",
    "            for name in names:\n",
    "                if name in file:\n",
    "                    w = pd.read_csv(os.path.join(location, pair, 'corrca_weights.csv'))\n",
    "                    corrca = fs.apply_corrCA_weights(df, w)\n",
    "                    corrca.to_csv(os.path.join(location, pair, \"selection\", f\"{p}_{name}_corrca.csv\"))\n",
    "                    continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
