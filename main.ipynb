{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main working file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "## system\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "## data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Rewrapping: \n",
    "\n",
    "\n",
    "NOT IMPLEMENTED - NEED TO ASK JULIETTE / IVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-in\\05_06\\VideoAudio\\pp05_navigator_reconstructed_video_and_audio_discussion_phase_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\05_06\\VideoAudio\\pp05_navigator_reconstructed_video_and_audio_discussion_phase_1.mp4\n",
      "Video already has metadata\n",
      "data-in\\05_06\\VideoAudio\\pp05_navigator_reconstructed_video_and_audio_instructional_video_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\05_06\\VideoAudio\\pp06_pilot_reconstructed_video_and_audio_discussion_phase_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\05_06\\VideoAudio\\pp06_pilot_reconstructed_video_and_audio_discussion_phase_1.mp4\n",
      "Video already has metadata\n",
      "data-in\\05_06\\VideoAudio\\pp06_pilot_reconstructed_video_and_audio_instructional_video_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\05_06\\VideoAudio\\test.mp4\n",
      "Video already has metadata\n",
      "data-in\\07_08\\VideoAudio\\pp07_navigator_reconstructed_video_and_audio_discussion_phase_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\07_08\\VideoAudio\\pp07_navigator_reconstructed_video_and_audio_discussion_phase_1.mp4\n",
      "Video already has metadata\n",
      "data-in\\07_08\\VideoAudio\\pp07_navigator_reconstructed_video_and_audio_instructional_video_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\07_08\\VideoAudio\\pp08_pilot_reconstructed_video_and_audio_discussion_phase_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\07_08\\VideoAudio\\pp08_pilot_reconstructed_video_and_audio_discussion_phase_1.mp4\n",
      "Video already has metadata\n",
      "data-in\\07_08\\VideoAudio\\pp08_pilot_reconstructed_video_and_audio_instructional_video_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\09_10\\VideoAudio\\pp09_navigator_reconstructed_video_and_audio_discussion_phase_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\09_10\\VideoAudio\\pp09_navigator_reconstructed_video_and_audio_discussion_phase_1.mp4\n",
      "Video already has metadata\n",
      "data-in\\09_10\\VideoAudio\\pp09_navigator_reconstructed_video_and_audio_instructional_video_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\09_10\\VideoAudio\\pp10_pilot_reconstructed_video_and_audio_discussion_phase_0.mp4\n",
      "Video already has metadata\n",
      "data-in\\09_10\\VideoAudio\\pp10_pilot_reconstructed_video_and_audio_discussion_phase_1.mp4\n",
      "Video already has metadata\n",
      "data-in\\09_10\\VideoAudio\\pp10_pilot_reconstructed_video_and_audio_instructional_video_0.mp4\n",
      "Video already has metadata\n"
     ]
    }
   ],
   "source": [
    "# Import the function\n",
    "from util.video_transformation import rewrap_video\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "path_source = r\"data-in\"\n",
    "path_output =    r\"data-in\"\n",
    "\n",
    "for team_folder in os.listdir(path_source):\n",
    "    path_videos = os.path.join(path_source, team_folder, \"VideoAudio\")\n",
    "    files = glob.glob(os.path.join(path_videos, \"*.mp4\"))\n",
    "\n",
    "    for file in files:\n",
    "        rewrap_video(file, path_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of Action Units (AUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pp05_navigator_instructional_video_0.csv has already been processed. Continuing...\n",
      "pp05_navigator_discussion_phase_0.csv has already been processed. Continuing...\n",
      "pp05_navigator_discussion_phase_1.csv has already been processed. Continuing...\n",
      "pp06_pilot_instructional_video_0.csv has already been processed. Continuing...\n",
      "pp06_pilot_discussion_phase_0.csv has already been processed. Continuing...\n",
      "pp06_pilot_discussion_phase_1.csv has already been processed. Continuing...\n",
      "pp07_navigator_instructional_video_0.csv has already been processed. Continuing...\n",
      "pp07_navigator_discussion_phase_0.csv has already been processed. Continuing...\n",
      "pp07_navigator_discussion_phase_1.csv has already been processed. Continuing...\n",
      "pp08_pilot_instructional_video_0.csv has already been processed. Continuing...\n",
      "pp08_pilot_discussion_phase_0.csv has already been processed. Continuing...\n",
      "pp08_pilot_discussion_phase_1.csv has already been processed. Continuing...\n",
      "pp09_navigator_instructional_video_0.csv has already been processed. Continuing...\n",
      "pp09_navigator_discussion_phase_0.csv has already been processed. Continuing...\n",
      "pp09_navigator_discussion_phase_1.csv has already been processed. Continuing...\n",
      "pp10_pilot_instructional_video_0.csv has already been processed. Continuing...\n",
      "pp10_pilot_discussion_phase_0.csv has already been processed. Continuing...\n",
      "pp10_pilot_discussion_phase_1.csv has already been processed. Continuing...\n"
     ]
    }
   ],
   "source": [
    "from util.feature_extraction import extract_features\n",
    "data_in = r'data-in'\n",
    "data_out = r'data-out'\n",
    "\n",
    "for pair in os.listdir(data_in):\n",
    "    input_folder = os.path.join(data_in, pair)\n",
    "    output_folder = os.path.join(data_out, pair, 'au')\n",
    "    for participant in pair.split('_'):\n",
    "        # TODO: handle missing data (NaN or recovered)\n",
    "        aus = extract_features(input_folder, participant, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['frame', ' face_id', ' timestamp', ' confidence', ' success', ' AU01_r',\n",
      "       ' AU02_r', ' AU04_r', ' AU05_r', ' AU06_r', ' AU07_r', ' AU09_r',\n",
      "       ' AU10_r', ' AU12_r', ' AU14_r', ' AU15_r', ' AU17_r', ' AU20_r',\n",
      "       ' AU23_r', ' AU25_r', ' AU26_r', ' AU45_r', ' AU01_c', ' AU02_c',\n",
      "       ' AU04_c', ' AU05_c', ' AU06_c', ' AU07_c', ' AU09_c', ' AU10_c',\n",
      "       ' AU12_c', ' AU14_c', ' AU15_c', ' AU17_c', ' AU20_c', ' AU23_c',\n",
      "       ' AU25_c', ' AU26_c', ' AU28_c', ' AU45_c'],\n",
      "      dtype='object')\n",
      "Index(['frame', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import util.feature_selection as fs\n",
    "location = r\"data-out\" \n",
    "for pair in os.listdir(location):\n",
    "    # TODO: make it check which pair the file is from and make two dataframes of that. Then combine\n",
    "    for file in os.listdir(os.path.join(location, pair, \"au\")):\n",
    "        filename = os.path.join(location, pair, \"au\", file)\n",
    "        fs.au_to_factors(pd.read_csv(filename)) # add this to dataframe\n",
    "\n",
    "# # au_to_factor input takes a dataframe as input, do this for every single au file.\n",
    "# print(fs.au_to_factors(df).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files of pairs in data-out\\05_06 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "(17, 17)\n",
      "files of pairs in data-out\\07_08 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "(17, 17)\n",
      "(17, 17)\n"
     ]
    }
   ],
   "source": [
    "import util.feature_selection as fs\n",
    "\n",
    "# corrCA takes a df as input. This df should be all files for a pair. \n",
    "location = r\"data-out\" \n",
    "for pair in os.listdir(location):\n",
    "    filename = os.path.join(location, pair)\n",
    "    data = {}\n",
    "    nav, pil = pair.split(\"_\")\n",
    "    nav_df = pd.DataFrame()\n",
    "    pil_df = pd.DataFrame()\n",
    "    for file in os.listdir(os.path.join(filename, \"au\")):\n",
    "        if \".csv\" in file and nav in file:\n",
    "            nav_df = pd.concat([nav_df, pd.read_csv(os.path.join(filename, \"au\", file))])\n",
    "        if \".csv\" in file and pil in file:\n",
    "            pil_df = pd.concat([pil_df, pd.read_csv(os.path.join(filename, \"au\", file))])\n",
    "    fs.corrCA(filename, nav_df, pil_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
