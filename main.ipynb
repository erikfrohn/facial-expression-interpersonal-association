{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main working file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "## system\n",
    "import glob\n",
    "import os\n",
    "\n",
    "## data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-in\\09_10\\avi\\Camera_pp10_navigator_0_20240703_1008.avi\n",
      "Rewrapping video\n",
      "Video was already rewrapped\n",
      "data-in\\09_10\\avi\\Camera_pp10_navigator_0_20240703_1008_rewrapped.avi\n",
      "Video already has metadata\n",
      "data-in\\09_10\\avi\\Camera_pp9_pilot_0_20240703_1008.avi\n",
      "Video already has metadata\n",
      "data-in\\21_22\\avi\\Camera_pp21_pilot_0_20240925_1339.avi\n",
      "Video already has metadata\n",
      "data-in\\21_22\\avi\\Camera_pp22_navigator_0_20240925_1338.avi\n",
      "Rewrapping video\n",
      "Video was already rewrapped\n",
      "data-in\\21_22\\avi\\Camera_pp22_navigator_0_20240925_1338_rewrapped.avi\n",
      "Video already has metadata\n"
     ]
    }
   ],
   "source": [
    "# Import the function\n",
    "from util.video_transformation import rewrap_video\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "base_path = \"data-in\"\n",
    "input_folder = \"avi\"\n",
    "\n",
    "for team_folder in os.listdir(base_path):\n",
    "    if team_folder not in ['09_10', '21_22']:\n",
    "        continue\n",
    "    path_videos = os.path.join(base_path, team_folder, input_folder, \"*.avi\")\n",
    "    files = glob.glob(path_videos)\n",
    "\n",
    "    for file in files:\n",
    "        rewrap_video(file, os.path.join(base_path, team_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge audio and video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from util.video_transformation import merge_audio_video\n",
    "\n",
    "# video_path = r'C:\\Users\\bruinj\\OneDrive - TNO\\Project Pages\\Team Metrics\\Team\\Work\\Experiment\\data\\21_22\\analysis\\pp21_navigator_reconstructed_video_2.avi'\n",
    "# audio_path = r'C:\\Users\\bruinj\\OneDrive - TNO\\Project Pages\\Team Metrics\\Team\\Work\\Experiment\\data\\21_22\\analysis\\navigator_21_discussion_phase_1_audio.wav'\n",
    "# output_path = r'C:\\Users\\bruinj\\OneDrive - TNO\\Project Pages\\Team Metrics\\Team\\Work\\Experiment\\data\\21_22\\analysis\\navigator_21_discussion_phase_1_audio_vid.avi'\n",
    "\n",
    "# merge_audio_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of Action Units (AUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05_06\n",
      "pp05_navigator_instructional_video_0 already processed, skipping\n",
      "pp06_pilot_instructional_video_0 already processed, skipping\n",
      "pp05_navigator_discussion_phase_0 already processed, skipping\n",
      "pp06_pilot_discussion_phase_0 already processed, skipping\n",
      "pp05_navigator_discussion_phase_1 already processed, skipping\n",
      "pp06_pilot_discussion_phase_1 already processed, skipping\n",
      "pp05_navigator_reschu_run_0 extraction\n"
     ]
    }
   ],
   "source": [
    "### all in one doc:\n",
    "import util.feature_extraction as fe\n",
    "import os\n",
    "\n",
    "openface_path = r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\OpenFace_2.2.0_win_x64\\OpenFace_2.2.0_win_x64\\OpenFace_2.2.0_win_x64\\FeatureExtraction.exe\"\n",
    "  \n",
    "data_in = r\"data\"\n",
    "data_out = r\"data-out\"\n",
    "folder = \"au\"\n",
    "phases = [(\"instructional_video\", 1), (\"discussion_phase\", 2), (\"reschu_run\", 8)]\n",
    "for i in range(5,100)[::2]:\n",
    "    j = i + 1\n",
    "    if i < 10: i = \"0\" + str(i)\n",
    "    if j < 10: j = \"0\" + str(j)\n",
    "    pair = f\"{i}_{j}\"\n",
    "    print(pair)\n",
    "    for phase, count in phases:\n",
    "        for c in range(count):\n",
    "            nav = f\"pp{i}_navigator_{phase}_{c}\"\n",
    "            pil = f\"pp{j}_pilot_{phase}_{c}\"\n",
    "            for participant in [nav, pil]:\n",
    "                input = os.path.join(data_in, participant + \"_reconstructed_video.avi\")\n",
    "                output = os.path.join(data_out, pair, folder, participant + \".csv\")\n",
    "                if os.path.exists(input):\n",
    "                    if os.path.exists(output):\n",
    "                        print(f\"{participant} already processed, skipping\")\n",
    "                        continue\n",
    "                    else:\n",
    "                        print(f\"{participant} extraction\")\n",
    "                        os.system(f\"{openface_path} -f \\\"{input}\\\" -aus -of \\\"{output}\\\"\")\n",
    "                else:\n",
    "                    print(f\"{participant} avi file does not exist in the input folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "cpu_count() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pp05_navigator_instructional_video_0.csv has already been processed. Continuing...\n",
      "pp05_navigator_discussion_phase_0.csv has already been processed. Continuing...\n",
      "pp05_navigator_discussion_phase_1.csv has already been processed. Continuing...\n",
      "pp06_pilot_instructional_video_0.csv has already been processed. Continuing...\n",
      "pp06_pilot_discussion_phase_0.csv has already been processed. Continuing...\n",
      "pp06_pilot_discussion_phase_1.csv has already been processed. Continuing...\n",
      "pp07_navigator_instructional_video_0.csv has already been processed. Continuing...\n",
      "pp07_navigator_discussion_phase_0.csv has already been processed. Continuing...\n",
      "pp07_navigator_discussion_phase_1.csv has already been processed. Continuing...\n",
      "pp08_pilot_instructional_video_0.csv has already been processed. Continuing...\n",
      "pp08_pilot_discussion_phase_0.csv has already been processed. Continuing...\n",
      "pp08_pilot_discussion_phase_1.csv has already been processed. Continuing...\n",
      "pp09_navigator_instructional_video_0.csv has already been processed. Continuing...\n",
      "pp09_navigator_discussion_phase_0.csv has already been processed. Continuing...\n",
      "pp09_navigator_discussion_phase_1.csv has already been processed. Continuing...\n",
      "pp10_pilot_instructional_video_0.csv has already been processed. Continuing...\n",
      "pp10_pilot_discussion_phase_0.csv has already been processed. Continuing...\n",
      "pp10_pilot_discussion_phase_1.csv has already been processed. Continuing...\n"
     ]
    }
   ],
   "source": [
    "### FOLLOWING OLD STRUCTURE\n",
    "# from util.feature_extraction import extract_features\n",
    "# data_in = r'data-in'\n",
    "# data_out = r'data-out'\n",
    "\n",
    "# for pair in os.listdir(data_in):\n",
    "#     if pair == \"21_22\":\n",
    "#         continue\n",
    "#     input_folder = os.path.join(data_in, pair)\n",
    "#     output_folder = os.path.join(data_out, pair, 'au')\n",
    "#     for participant in pair.split('_'):\n",
    "#         # TODO: handle missing data (NaN or recovered)\n",
    "#         if os.path.exists(input_folder):\n",
    "#             aus = extract_features(input_folder, participant, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.feature_selection as fs\n",
    "\n",
    "location = r\"data-out\" \n",
    "for pair in os.listdir(location):\n",
    "    filename = os.path.join(location, pair, \"selection\")\n",
    "    os.makedirs(filename, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['discussion_phase_0', 'discussion_phase_1', 'instructional_video_0']\n",
    "for pair in os.listdir(location):\n",
    "    # TODO: make it check which pair the file is from and make two dataframes of that. Then combine\n",
    "    for file in os.listdir(os.path.join(location, pair, \"au\")):\n",
    "        if \".csv\" in file: \n",
    "            filename = os.path.join(location, pair, \"au\", file)\n",
    "            participant, _ = file.split(\"_\",1)\n",
    "            df = pd.read_csv(filename)\n",
    "            for name in names:\n",
    "                if name in file:\n",
    "                    factors = fs.au_to_factors(df)\n",
    "                    factors.to_csv(os.path.join(location, pair, \"selection\", f\"{participant}_{name}_factors.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files of pairs in 05_06 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "(17, 17)\n",
      "files of pairs in 07_08 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "(17, 17)\n",
      "(17, 17)\n"
     ]
    }
   ],
   "source": [
    "# corrCA takes a df as input. This df should be all files for a pair. \n",
    "\n",
    "for pair in os.listdir(location):\n",
    "    filename = os.path.join(location, pair)\n",
    "    data = {}\n",
    "    nav, pil = pair.split(\"_\")\n",
    "    nav_df = pd.DataFrame()\n",
    "    pil_df = pd.DataFrame()\n",
    "    # add all phases to a single dataframe\n",
    "    for file in os.listdir(os.path.join(filename, \"au\")):\n",
    "        if \".csv\" in file: \n",
    "            df = pd.read_csv(os.path.join(filename, \"au\", file))\n",
    "            if \".csv\" in file and nav in file:\n",
    "                nav_df = pd.concat([nav_df, df])\n",
    "            if \".csv\" in file and pil in file:\n",
    "                pil_df = pd.concat([pil_df, df])\n",
    "    nav_df, pil_df = fs.make_equal_length(pair, nav_df, pil_df)\n",
    "    w = fs.corrCA_weights(nav_df, pil_df) #output = pair/pair_corrca_weights.csv\n",
    "    w.to_csv(os.path.join(filename, f\"{pair}_corrca_weights.csv\"), index=False)\n",
    "\n",
    "names = ['discussion_phase_0', 'discussion_phase_1', 'instructional_video_0']\n",
    "for pair in os.listdir(location):\n",
    "    for file in os.listdir(os.path.join(location, pair, \"au\")):\n",
    "        if \".csv\" in file: \n",
    "            filename = os.path.join(location, pair, \"au\", file)\n",
    "            participant, _ = file.split(\"_\", 1)\n",
    "            df = pd.read_csv(filename)\n",
    "            for name in names:\n",
    "                if name in file:\n",
    "                    w = pd.read_csv(os.path.join(location, pair, f'{pair}_corrca_weights.csv'))\n",
    "                    corrca = fs.apply_corrCA_weights(df, w)\n",
    "                    corrca.to_csv(os.path.join(location, pair, \"selection\", f\"{participant}_{name}_corrca.csv\"), index=False)\n",
    "                    continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytools\\persistent_dict.py:52: RecommendedHashNotFoundWarning: Unable to import recommended hash 'siphash24.siphash13', falling back to 'hashlib.sha256'. Run 'python3 -m pip install siphash24' to install the recommended hash.\n",
      "  warn(\"Unable to import recommended hash 'siphash24.siphash13', \"\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import util.feature_selection as fs\n",
    "import util.correlation_measure as cm\n",
    "\n",
    "location = r\"data-out\" \n",
    "\n",
    "for pair in os.listdir(location):\n",
    "    filename = os.path.join(location, pair, \"extraction\")\n",
    "    os.makedirs(filename, exist_ok=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files of pairs in 05_06_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 05_06_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_discussion_phase_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_discussion_phase_1 do not have the same amount of datapoints - temporary fix has made them equal length\n"
     ]
    }
   ],
   "source": [
    "sets = ['corrca', 'factors']\n",
    "phases = ['instructional_video_0', 'discussion_phase_0', 'discussion_phase_1']\n",
    "factors = ['f1', 'f2', 'f3', 'f4', 'f5', 'f6']\n",
    "\n",
    "# each pair gets a separate file\n",
    "for pair in os.listdir(location):\n",
    "    df = pd.DataFrame()\n",
    "    nav, pil = pair.split(\"_\")\n",
    "    file = os.path.join(location, pair, 'selection')\n",
    "\n",
    "    # format:  | factor1 | factor2 | ... | factor 6 | corrca | (per phase)\n",
    "    for phase in phases:\n",
    "        correlation = []\n",
    "        # factors\n",
    "        nav_factors = pd.read_csv(os.path.join(file, f\"pp{nav}_{phase}_factors.csv\"))\n",
    "        pil_factors = pd.read_csv(os.path.join(file, f\"pp{pil}_{phase}_factors.csv\"))\n",
    "        nav_factors, pil_factors = fs.make_equal_length(f\"{pair}_{phase}\", nav_factors, pil_factors)\n",
    "        for f in factors:\n",
    "            corr, _ = pearsonr(nav_factors[f].values, pil_factors[f].values)\n",
    "            correlation.append(corr)\n",
    "\n",
    "        # corrca\n",
    "        nav_corrca = pd.read_csv(os.path.join(file, f\"pp{nav}_{phase}_corrca.csv\"))\n",
    "        pil_corrca = pd.read_csv(os.path.join(file, f\"pp{pil}_{phase}_corrca.csv\"))\n",
    "        nav_corrca, pil_corrca = fs.make_equal_length(f\"{pair}_{phase}\", nav_corrca, pil_corrca)\n",
    "        \n",
    "        corr, _ = pearsonr(nav_corrca['component1'].values, pil_corrca['component1'].values)\n",
    "        correlation.append(corr)\n",
    "        \n",
    "        df[phase] = correlation\n",
    "    \n",
    "    # for participant-wise saving\n",
    "    df.to_csv(os.path.join(location, pair, \"extraction\", f\"{pair}_pearson.csv\"))\n",
    "    \n",
    "    # for easy access saving\n",
    "    df.to_csv(os.path.join(\"results\", f\"{pair}_pearson.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cRQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nav = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp07_discussion_phase_0_factors.csv\")\n",
    "# pil = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp08_discussion_phase_0_factors.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# for f in factors:\n",
    "#     cm.crqa(f, nav[f].values, pil[f].values) \n",
    "\n",
    "\n",
    "# nav = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp07_discussion_phase_0_factors.csv\")\n",
    "# pil = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp08_discussion_phase_0_factors.csv\")\n",
    "\n",
    "# cm.crqa3(nav.iloc[1:].values, pil.iloc[1:].values)\n",
    "\n",
    "\n",
    "# nav = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp07_discussion_phase_0_factors.csv\")\n",
    "# pil = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp08_discussion_phase_0_factors.csv\")\n",
    "\n",
    "# cm.mimicry(nav.iloc[1:].values, pil.iloc[1:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Platform 'Intel(R) OpenCL HD Graphics']\n",
      "Vendor: Intel(R) Corporation\n",
      "Version: OpenCL 2.1 \n",
      "Profile: FULL_PROFILE\n",
      "Extensions: cl_khr_byte_addressable_store cl_khr_fp16 cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_icd cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_intel_subgroups cl_intel_required_subgroup_size cl_intel_subgroups_short cl_khr_spir cl_intel_accelerator cl_intel_driver_diagnostics cl_khr_priority_hints cl_khr_throttle_hints cl_khr_create_command_queue cl_intel_subgroups_char cl_intel_subgroups_long cl_khr_il_program cl_khr_fp64 cl_khr_subgroups cl_intel_spirv_device_side_avc_motion_estimation cl_intel_spirv_media_block_io cl_intel_spirv_subgroups cl_khr_spirv_no_integer_wrap_decoration cl_intel_unified_shared_memory_preview cl_khr_mipmap_image cl_khr_mipmap_image_writes cl_intel_planar_yuv cl_intel_packed_yuv cl_intel_motion_estimation cl_intel_device_side_avc_motion_estimation cl_intel_advanced_motion_estimation cl_khr_int64_base_atomics cl_khr_int64_extended_atomics cl_khr_image2d_from_buffer cl_khr_depth_images cl_intel_media_block_io cl_khr_3d_image_writes cl_khr_gl_sharing cl_khr_gl_depth_images cl_khr_gl_event cl_khr_gl_msaa_sharing cl_intel_dx9_media_sharing cl_khr_dx9_media_sharing cl_khr_d3d10_sharing cl_khr_d3d11_sharing cl_intel_d3d11_nv12_media_sharing cl_intel_unified_sharing cl_intel_simultaneous_sharing \n",
      "\n",
      "\n",
      "[Device 'Intel(R) UHD Graphics 620']\n",
      "Vendor: Intel(R) Corporation\n",
      "Type: 4\n",
      "Version: OpenCL 2.1 NEO \n",
      "Profile: FULL_PROFILE\n",
      "Max Clock Frequency: 1100\n",
      "Global Mem Size: 3383427072\n",
      "Address Bits: 64\n",
      "Max Compute Units: 24\n",
      "Max Work Group Size: 256\n",
      "Max Work Item Dimensions: 3\n",
      "Max Work Item Sizes: [256, 256, 256]\n",
      "Local Mem Size: 65536\n",
      "Max Mem Alloc Size: 1691713536\n",
      "Extensions: cl_khr_byte_addressable_store cl_khr_fp16 cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_icd cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_intel_subgroups cl_intel_required_subgroup_size cl_intel_subgroups_short cl_khr_spir cl_intel_accelerator cl_intel_driver_diagnostics cl_khr_priority_hints cl_khr_throttle_hints cl_khr_create_command_queue cl_intel_subgroups_char cl_intel_subgroups_long cl_khr_il_program cl_khr_fp64 cl_khr_subgroups cl_intel_spirv_device_side_avc_motion_estimation cl_intel_spirv_media_block_io cl_intel_spirv_subgroups cl_khr_spirv_no_integer_wrap_decoration cl_intel_unified_shared_memory_preview cl_khr_mipmap_image cl_khr_mipmap_image_writes cl_intel_planar_yuv cl_intel_packed_yuv cl_intel_motion_estimation cl_intel_device_side_avc_motion_estimation cl_intel_advanced_motion_estimation cl_khr_int64_base_atomics cl_khr_int64_extended_atomics cl_khr_image2d_from_buffer cl_khr_depth_images cl_intel_media_block_io cl_khr_3d_image_writes cl_khr_gl_sharing cl_khr_gl_depth_images cl_khr_gl_event cl_khr_gl_msaa_sharing cl_intel_dx9_media_sharing cl_khr_dx9_media_sharing cl_khr_d3d10_sharing cl_khr_d3d11_sharing cl_intel_d3d11_nv12_media_sharing cl_intel_unified_sharing cl_intel_simultaneous_sharing \n",
      "\n",
      "\n",
      "CRQA Result:\n",
      "============\n",
      "\n",
      "Minimum diagonal line length (L_min): 2\n",
      "Minimum vertical line length (V_min): 2\n",
      "Minimum white vertical line length (W_min): 2\n",
      "\n",
      "Recurrence rate (RR): 0.384898\n",
      "Determinism (DET): 0.978732\n",
      "Average diagonal line length (L): 9.808382\n",
      "Longest diagonal line length (L_max): 267\n",
      "Divergence (DIV): 0.003745\n",
      "Entropy diagonal lines (L_entr): 2.926366\n",
      "Laminarity (LAM): 0.996109\n",
      "Trapping time (TT): 34.852825\n",
      "Longest vertical line length (V_max): 3083\n",
      "Entropy vertical lines (V_entr): 3.832189\n",
      "Average white vertical line length (W): 56.225044\n",
      "Longest white vertical line length (W_max): 9001\n",
      "Longest white vertical line length inverse (W_div): 0.000111\n",
      "Entropy white vertical lines (W_entr): 3.949916\n",
      "\n",
      "Ratio determinism / recurrence rate (DET/RR): 2.542834\n",
      "Ratio laminarity / determinism (LAM/DET): 1.017755\n",
      "\n",
      "[Platform 'Intel(R) OpenCL HD Graphics']\n",
      "Vendor: Intel(R) Corporation\n",
      "Version: OpenCL 2.1 \n",
      "Profile: FULL_PROFILE\n",
      "Extensions: cl_khr_byte_addressable_store cl_khr_fp16 cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_icd cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_intel_subgroups cl_intel_required_subgroup_size cl_intel_subgroups_short cl_khr_spir cl_intel_accelerator cl_intel_driver_diagnostics cl_khr_priority_hints cl_khr_throttle_hints cl_khr_create_command_queue cl_intel_subgroups_char cl_intel_subgroups_long cl_khr_il_program cl_khr_fp64 cl_khr_subgroups cl_intel_spirv_device_side_avc_motion_estimation cl_intel_spirv_media_block_io cl_intel_spirv_subgroups cl_khr_spirv_no_integer_wrap_decoration cl_intel_unified_shared_memory_preview cl_khr_mipmap_image cl_khr_mipmap_image_writes cl_intel_planar_yuv cl_intel_packed_yuv cl_intel_motion_estimation cl_intel_device_side_avc_motion_estimation cl_intel_advanced_motion_estimation cl_khr_int64_base_atomics cl_khr_int64_extended_atomics cl_khr_image2d_from_buffer cl_khr_depth_images cl_intel_media_block_io cl_khr_3d_image_writes cl_khr_gl_sharing cl_khr_gl_depth_images cl_khr_gl_event cl_khr_gl_msaa_sharing cl_intel_dx9_media_sharing cl_khr_dx9_media_sharing cl_khr_d3d10_sharing cl_khr_d3d11_sharing cl_intel_d3d11_nv12_media_sharing cl_intel_unified_sharing cl_intel_simultaneous_sharing \n",
      "\n",
      "\n",
      "[Device 'Intel(R) UHD Graphics 620']\n",
      "Vendor: Intel(R) Corporation\n",
      "Type: 4\n",
      "Version: OpenCL 2.1 NEO \n",
      "Profile: FULL_PROFILE\n",
      "Max Clock Frequency: 1100\n",
      "Global Mem Size: 3383427072\n",
      "Address Bits: 64\n",
      "Max Compute Units: 24\n",
      "Max Work Group Size: 256\n",
      "Max Work Item Dimensions: 3\n",
      "Max Work Item Sizes: [256, 256, 256]\n",
      "Local Mem Size: 65536\n",
      "Max Mem Alloc Size: 1691713536\n",
      "Extensions: cl_khr_byte_addressable_store cl_khr_fp16 cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_icd cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_intel_subgroups cl_intel_required_subgroup_size cl_intel_subgroups_short cl_khr_spir cl_intel_accelerator cl_intel_driver_diagnostics cl_khr_priority_hints cl_khr_throttle_hints cl_khr_create_command_queue cl_intel_subgroups_char cl_intel_subgroups_long cl_khr_il_program cl_khr_fp64 cl_khr_subgroups cl_intel_spirv_device_side_avc_motion_estimation cl_intel_spirv_media_block_io cl_intel_spirv_subgroups cl_khr_spirv_no_integer_wrap_decoration cl_intel_unified_shared_memory_preview cl_khr_mipmap_image cl_khr_mipmap_image_writes cl_intel_planar_yuv cl_intel_packed_yuv cl_intel_motion_estimation cl_intel_device_side_avc_motion_estimation cl_intel_advanced_motion_estimation cl_khr_int64_base_atomics cl_khr_int64_extended_atomics cl_khr_image2d_from_buffer cl_khr_depth_images cl_intel_media_block_io cl_khr_3d_image_writes cl_khr_gl_sharing cl_khr_gl_depth_images cl_khr_gl_event cl_khr_gl_msaa_sharing cl_intel_dx9_media_sharing cl_khr_dx9_media_sharing cl_khr_d3d10_sharing cl_khr_d3d11_sharing cl_intel_d3d11_nv12_media_sharing cl_intel_unified_sharing cl_intel_simultaneous_sharing \n",
      "\n",
      "\n",
      "CRQA Result:\n",
      "============\n",
      "\n",
      "Minimum diagonal line length (L_min): 2\n",
      "Minimum vertical line length (V_min): 2\n",
      "Minimum white vertical line length (W_min): 2\n",
      "\n",
      "Recurrence rate (RR): 0.088713\n",
      "Determinism (DET): 0.960120\n",
      "Average diagonal line length (L): 7.035992\n",
      "Longest diagonal line length (L_max): 180\n",
      "Divergence (DIV): 0.005556\n",
      "Entropy diagonal lines (L_entr): 2.609403\n",
      "Laminarity (LAM): 0.974449\n",
      "Trapping time (TT): 13.671096\n",
      "Longest vertical line length (V_max): 2336\n",
      "Entropy vertical lines (V_entr): 3.211786\n",
      "Average white vertical line length (W): 118.231997\n",
      "Longest white vertical line length (W_max): 9001\n",
      "Longest white vertical line length inverse (W_div): 0.000111\n",
      "Entropy white vertical lines (W_entr): 4.629499\n",
      "\n",
      "Ratio determinism / recurrence rate (DET/RR): 10.822783\n",
      "Ratio laminarity / determinism (LAM/DET): 1.014924\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<pyrqa.result.RQAResult at 0x29edef61130>,\n",
       " <pyrqa.result.RPResult at 0x29e8003ba40>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nav = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp07_discussion_phase_0_factors.csv\")\n",
    "pil = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp08_discussion_phase_0_factors.csv\")\n",
    "\n",
    "cm.crqa(\"fac\",nav['f1'].values, pil['f2'].values)\n",
    "\n",
    "nav = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp07_discussion_phase_0_corrca.csv\")\n",
    "pil = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp08_discussion_phase_0_corrca.csv\")\n",
    "\n",
    "cm.crqa(\"cor\",nav['component1'].values, pil['component1'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
