{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main working file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "## system\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import util.feature_extraction as fe\n",
    "import util.feature_selection as fs\n",
    "import util.correlation_measure as cm\n",
    "import util.video_transformation as vt\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "LOCATION = \"data\"\n",
    "ACTION_UNITS = \"au\"\n",
    "FEATURE_FOLDER = \"features\"\n",
    "CORRELATION_FOLDER = 'correlations'\n",
    "PHASES = [f'{name}_{i}' for name, num in  [(\"instructional_video\", 1), (\"discussion_phase\", 2), (\"reschu_run\", 8)] for i in range(num)]\n",
    "SETS = ['corrca', 'factors']\n",
    "\n",
    "for pair in os.listdir(LOCATION):\n",
    "    filename = os.path.join(LOCATION, pair, FEATURE_FOLDER)\n",
    "    os.makedirs(filename, exist_ok=True)\n",
    "    filename = os.path.join(LOCATION, pair, CORRELATION_FOLDER)\n",
    "    os.makedirs(filename, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the function\n",
    "# from util.video_transformation import rewrap_video\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2 \n",
    "\n",
    "# base_path = \"data-in\"\n",
    "# input_folder = \"avi\"\n",
    "\n",
    "# for team_folder in os.listdir(base_path):\n",
    "#     if team_folder not in ['09_10', '21_22']:\n",
    "#         continue\n",
    "#     path_videos = os.path.join(base_path, team_folder, input_folder, \"*.avi\")\n",
    "#     files = glob.glob(path_videos)\n",
    "\n",
    "#     for file in files:\n",
    "#         rewrap_video(file, os.path.join(base_path, team_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge audio and video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from util.video_transformation import merge_audio_video\n",
    "\n",
    "# video_path = r'C:\\Users\\bruinj\\OneDrive - TNO\\Project Pages\\Team Metrics\\Team\\Work\\Experiment\\data\\21_22\\analysis\\pp21_navigator_reconstructed_video_2.avi'\n",
    "# audio_path = r'C:\\Users\\bruinj\\OneDrive - TNO\\Project Pages\\Team Metrics\\Team\\Work\\Experiment\\data\\21_22\\analysis\\navigator_21_discussion_phase_1_audio.wav'\n",
    "# output_path = r'C:\\Users\\bruinj\\OneDrive - TNO\\Project Pages\\Team Metrics\\Team\\Work\\Experiment\\data\\21_22\\analysis\\navigator_21_discussion_phase_1_audio_vid.avi'\n",
    "\n",
    "# merge_audio_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of Action Units (AUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### all in one doc:\n",
    "# import util.feature_extraction as fe\n",
    "# import os\n",
    "\n",
    "# openface_path = r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\OpenFace_2.2.0_win_x64\\OpenFace_2.2.0_win_x64\\OpenFace_2.2.0_win_x64\\FeatureExtraction.exe\"\n",
    "  \n",
    "# data_in = r\"data\"\n",
    "# data_out = r\"data-out\"\n",
    "# folder = \"au\"\n",
    "# phases = [(\"instructional_video\", 1), (\"discussion_phase\", 2), (\"reschu_run\", 8)]\n",
    "# for i in range(5,100)[::2]:\n",
    "#     j = i + 1\n",
    "#     if i < 10: i = \"0\" + str(i)\n",
    "#     if j < 10: j = \"0\" + str(j)\n",
    "#     pair = f\"{i}_{j}\"\n",
    "#     print(pair)\n",
    "#     for phase, count in phases:\n",
    "#         for c in range(count):\n",
    "#             nav = f\"pp{i}_navigator_{phase}_{c}\"\n",
    "#             pil = f\"pp{j}_pilot_{phase}_{c}\"\n",
    "#             for participant in [nav, pil]:\n",
    "#                 input = os.path.join(data_in, participant + \"_reconstructed_video.avi\")\n",
    "#                 output = os.path.join(data_out, pair, folder, participant + \".csv\")\n",
    "#                 if os.path.exists(input):\n",
    "#                     if os.path.exists(output):\n",
    "#                         print(f\"{participant} already processed, skipping\")\n",
    "#                         continue\n",
    "#                     else:\n",
    "#                         print(f\"{participant} extraction\")\n",
    "#                         os.system(f\"{openface_path} -f \\\"{input}\\\" -aus -of \\\"{output}\\\"\")\n",
    "#                 else:\n",
    "#                     print(f\"{participant} avi file does not exist in the input folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOLLOWING OLD STRUCTURE\n",
    "# from util.feature_extraction import extract_features\n",
    "# data_in = r'data-in'\n",
    "# data_out = r'data-out'\n",
    "\n",
    "# for pair in os.listdir(data_in):\n",
    "#     if pair == \"21_22\":\n",
    "#         continue\n",
    "#     input_folder = os.path.join(data_in, pair)\n",
    "#     output_folder = os.path.join(data_out, pair, 'au')\n",
    "#     for participant in pair.split('_'):\n",
    "#         # TODO: handle missing data (NaN or recovered)\n",
    "#         if os.path.exists(input_folder):\n",
    "#             aus = extract_features(input_folder, participant, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTRACTING FACIAL FACTORS FOR EACH FILE SEPARATELY\n",
    "for pair in os.listdir(LOCATION):\n",
    "    for file in os.listdir(os.path.join(LOCATION, pair, ACTION_UNITS)):\n",
    "        if \".csv\" in file: \n",
    "            filename = os.path.join(LOCATION, pair, ACTION_UNITS, file)\n",
    "            participant, _ = file.split(\"_\",1)\n",
    "            df = pd.read_csv(filename)\n",
    "            for name in PHASES:\n",
    "                if name in file:\n",
    "                    factors = fs.au_to_factors(df)\n",
    "                    factors.to_csv(os.path.join(LOCATION, pair, FEATURE_FOLDER, f\"{participant}_{name}_factors.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files of pairs in 05_06 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "(17, 17)\n",
      "files of pairs in 07_08 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "(17, 17)\n",
      "files of pairs in 09_10 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "(17, 17)\n",
      "files of pairs in 11_12 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "(17, 17)\n",
      "files of pairs in 13_14 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "(17, 17)\n",
      "files of pairs in 17_18 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "(17, 17)\n",
      "files of pairs in 19_20 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "(17, 17)\n",
      "files of pairs in 25_26 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "(17, 17)\n",
      "files of pairs in 27_28 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "(17, 17)\n",
      "files of pairs in 29_30 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "(17, 17)\n",
      "files of pairs in 31_32 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "(17, 17)\n"
     ]
    }
   ],
   "source": [
    "## CREATING WEIGHTS FOR EACH PAIR SEPARATELY\n",
    "\n",
    "# corrCA takes a df as input. This df should be all files for a pair. \n",
    "for pair in os.listdir(LOCATION):\n",
    "    filename = os.path.join(LOCATION, pair)\n",
    "    data = {}\n",
    "    nav, pil = pair.split(\"_\")\n",
    "    # if int(nav) > 14: # TODO: remove when all AUs are there\n",
    "    #     break\n",
    "    nav_df = pd.DataFrame()\n",
    "    pil_df = pd.DataFrame()\n",
    "    # add all phases to a single dataframe\n",
    "    for file in os.listdir(os.path.join(filename, ACTION_UNITS)):\n",
    "        if \".csv\" in file: \n",
    "            df = pd.read_csv(os.path.join(filename, ACTION_UNITS, file))\n",
    "            if \".csv\" in file and nav in file:\n",
    "                nav_df = pd.concat([nav_df, df])\n",
    "            if \".csv\" in file and pil in file:\n",
    "                pil_df = pd.concat([pil_df, df])\n",
    "    nav_df, pil_df = fs.make_equal_length(pair, nav_df, pil_df)\n",
    "    w = fs.corrCA_weights(nav_df, pil_df) #output = pair/pair_corrca_weights.csv\n",
    "    w.to_csv(os.path.join(filename, f\"{pair}_corrca_weights.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## APPLYING CORRCA WEIGHTS TO EACH FILE SEPARATELY\n",
    "\n",
    "for pair in os.listdir(LOCATION):\n",
    "    loc = os.path.join(LOCATION, pair, f'{pair}_corrca_weights.csv')\n",
    "    if not os.path.exists(loc):\n",
    "        break\n",
    "    w = pd.read_csv(os.path.join(LOCATION, pair, f'{pair}_corrca_weights.csv'))\n",
    "    for file in os.listdir(os.path.join(LOCATION, pair, ACTION_UNITS)):\n",
    "        if \".csv\" in file: \n",
    "            filename = os.path.join(LOCATION, pair, ACTION_UNITS, file)\n",
    "            participant, _ = file.split(\"_\", 1)\n",
    "            df = pd.read_csv(filename)\n",
    "            for name in PHASES:\n",
    "                if name in file:\n",
    "                    corrca = fs.apply_corrCA_weights(df, w)\n",
    "                    corrca.to_csv(os.path.join(LOCATION, pair, FEATURE_FOLDER, f\"{participant}_{name}_corrca.csv\"), index=False)\n",
    "                    continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make the factors and corrca components binary \n",
    "# # scale them to -1, 1\n",
    "\n",
    "# df = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\05_06\\selection\\pp05_discussion_phase_0_factors.csv\")\n",
    "# df = df.drop(columns=['frame'])\n",
    "\n",
    "# print(df.values[:3])\n",
    "\n",
    "\n",
    "# df = cm.binarize_components(df.values)\n",
    "# print(df[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files of pairs in 05_06_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 05_06_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 05_06_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 05_06_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 05_06_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 05_06_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 05_06_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 05_06_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 05_06_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 05_06_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 05_06_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 05_06_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 05_06_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 05_06_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 05_06_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 05_06_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 05_06_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 05_06_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_discussion_phase_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_discussion_phase_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 07_08_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 09_10_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 09_10_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 09_10_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 09_10_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 09_10_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 09_10_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 09_10_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 09_10_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 09_10_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 09_10_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 09_10_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 09_10_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 09_10_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 09_10_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 09_10_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 09_10_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 11_12_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 11_12_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 11_12_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 11_12_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "11_12_discussion_phase_1_corrca misses files, skipping entire discussion_phase_1 for 11_12\n",
      "11_12_reschu_run_0_corrca misses files, skipping entire reschu_run_0 for 11_12\n",
      "11_12_reschu_run_1_corrca misses files, skipping entire reschu_run_1 for 11_12\n",
      "11_12_reschu_run_2_corrca misses files, skipping entire reschu_run_2 for 11_12\n",
      "11_12_reschu_run_3_corrca misses files, skipping entire reschu_run_3 for 11_12\n",
      "11_12_reschu_run_4_corrca misses files, skipping entire reschu_run_4 for 11_12\n",
      "11_12_reschu_run_5_corrca misses files, skipping entire reschu_run_5 for 11_12\n",
      "11_12_reschu_run_6_corrca misses files, skipping entire reschu_run_6 for 11_12\n",
      "11_12_reschu_run_7_corrca misses files, skipping entire reschu_run_7 for 11_12\n",
      "files of pairs in 13_14_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Erik\\AppData\\Local\\Temp\\ipykernel_15284\\3125120916.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n",
      "C:\\Users\\Erik\\AppData\\Local\\Temp\\ipykernel_15284\\3125120916.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n",
      "C:\\Users\\Erik\\AppData\\Local\\Temp\\ipykernel_15284\\3125120916.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n",
      "C:\\Users\\Erik\\AppData\\Local\\Temp\\ipykernel_15284\\3125120916.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files of pairs in 13_14_discussion_phase_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_discussion_phase_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Erik\\AppData\\Local\\Temp\\ipykernel_15284\\3125120916.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n",
      "C:\\Users\\Erik\\AppData\\Local\\Temp\\ipykernel_15284\\3125120916.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files of pairs in 13_14_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 13_14_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_discussion_phase_1 do not have the same amount of datapoints - temporary fix has made them equal length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Erik\\AppData\\Local\\Temp\\ipykernel_15284\\3125120916.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n",
      "C:\\Users\\Erik\\AppData\\Local\\Temp\\ipykernel_15284\\3125120916.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n",
      "C:\\Users\\Erik\\AppData\\Local\\Temp\\ipykernel_15284\\3125120916.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n",
      "C:\\Users\\Erik\\AppData\\Local\\Temp\\ipykernel_15284\\3125120916.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files of pairs in 17_18_discussion_phase_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Erik\\AppData\\Local\\Temp\\ipykernel_15284\\3125120916.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n",
      "C:\\Users\\Erik\\AppData\\Local\\Temp\\ipykernel_15284\\3125120916.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files of pairs in 17_18_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 17_18_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_discussion_phase_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_discussion_phase_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 19_20_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_discussion_phase_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_discussion_phase_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 25_26_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_discussion_phase_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_discussion_phase_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 27_28_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_discussion_phase_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_discussion_phase_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Erik\\AppData\\Local\\Temp\\ipykernel_15284\\3125120916.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n",
      "C:\\Users\\Erik\\AppData\\Local\\Temp\\ipykernel_15284\\3125120916.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n",
      "C:\\Users\\Erik\\AppData\\Local\\Temp\\ipykernel_15284\\3125120916.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n",
      "C:\\Users\\Erik\\AppData\\Local\\Temp\\ipykernel_15284\\3125120916.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n",
      "C:\\Users\\Erik\\AppData\\Local\\Temp\\ipykernel_15284\\3125120916.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files of pairs in 29_30_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Erik\\AppData\\Local\\Temp\\ipykernel_15284\\3125120916.py:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files of pairs in 29_30_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 29_30_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_instructional_video_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_discussion_phase_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_discussion_phase_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_discussion_phase_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_reschu_run_0 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_reschu_run_1 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_reschu_run_2 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_reschu_run_3 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_reschu_run_4 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_reschu_run_5 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_reschu_run_6 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "files of pairs in 31_32_reschu_run_7 do not have the same amount of datapoints - temporary fix has made them equal length\n"
     ]
    }
   ],
   "source": [
    "# extract pearson correlation for each file for both facial factors and corrca features\n",
    "for pair in os.listdir(LOCATION):\n",
    "    df = pd.DataFrame()\n",
    "    nav, pil = pair.split(\"_\")\n",
    "    file = os.path.join(LOCATION, pair, FEATURE_FOLDER)\n",
    "\n",
    "    for phase in PHASES:\n",
    "        correlation = []\n",
    "\n",
    "        for condition in SETS:\n",
    "            # do not process if it does not exists\n",
    "            nav_file = os.path.join(os.path.join(file, f\"pp{nav}_{phase}_{condition}.csv\"))\n",
    "            pil_file = os.path.join(os.path.join(file, f\"pp{pil}_{phase}_{condition}.csv\"))\n",
    "            if not os.path.exists(nav_file) or not os.path.exists(pil_file):\n",
    "                print(f\"{pair}_{phase}_{condition} misses files, skipping entire {phase} for {pair}\")\n",
    "                break\n",
    "\n",
    "            # process\n",
    "            nav_df = pd.read_csv(nav_file)\n",
    "            pil_df = pd.read_csv(pil_file)\n",
    "            nav_df, pil_df = fs.make_equal_length(f\"{pair}_{phase}\", nav_df, pil_df)\n",
    "            for i in range(1,nav_df.shape[1]):\n",
    "                corr, _ = pearsonr(nav_df[f'f{i}'].values, pil_df[f'f{i}'].values)\n",
    "                correlation.append(corr)\n",
    "        if correlation: \n",
    "            df[phase] = correlation\n",
    "\n",
    "    # for participant-wise saving\n",
    "    df.to_csv(os.path.join(LOCATION, pair, CORRELATION_FOLDER, f\"{pair}_pearson.csv\"))\n",
    "    \n",
    "    # for easy access saving\n",
    "    df.to_csv(os.path.join(\"results\", f\"{pair}_pearson.csv\"))\n",
    "\n",
    "# SETS = ['corrca', 'factors']\n",
    "# PHASES = ['instructional_video_0', 'discussion_phase_0', 'discussion_phase_1']\n",
    "# factors = ['f1', 'f2', 'f3', 'f4', 'f5', 'f6']\n",
    "\n",
    "# # each pair gets a separate file\n",
    "# for pair in os.listdir(LOCATION):\n",
    "#     df = pd.DataFrame()\n",
    "#     nav, pil = pair.split(\"_\")\n",
    "#     file = os.path.join(LOCATION, pair, CORRELATION_FOLDER)\n",
    "\n",
    "#     # format:  | factor1 | factor2 | ... | factor 6 | corrca | (per phase)\n",
    "#     for phase in PHASES:\n",
    "#         correlation = []\n",
    "#         # factors\n",
    "#         nav_factors = pd.read_csv(os.path.join(file, f\"pp{nav}_{phase}_factors.csv\"))\n",
    "#         pil_factors = pd.read_csv(os.path.join(file, f\"pp{pil}_{phase}_factors.csv\"))\n",
    "#         nav_factors, pil_factors = fs.make_equal_length(f\"{pair}_{phase}\", nav_factors, pil_factors)\n",
    "#         for f in factors:\n",
    "#             corr, _ = pearsonr(nav_factors[f].values, pil_factors[f].values)\n",
    "#             correlation.append(corr)\n",
    "\n",
    "#         # corrca\n",
    "#         nav_corrca = pd.read_csv(os.path.join(file, f\"pp{nav}_{phase}_corrca.csv\"))\n",
    "#         pil_corrca = pd.read_csv(os.path.join(file, f\"pp{pil}_{phase}_corrca.csv\"))\n",
    "#         nav_corrca, pil_corrca = fs.make_equal_length(f\"{pair}_{phase}\", nav_corrca, pil_corrca)\n",
    "        \n",
    "#         corr, _ = pearsonr(nav_corrca['component1'].values, pil_corrca['component1'].values)\n",
    "#         correlation.append(corr)\n",
    "        \n",
    "#         df[phase] = correlation\n",
    "    \n",
    "#     # for participant-wise saving\n",
    "#     df.to_csv(os.path.join(LOCATION, pair, \"extraction\", f\"{pair}_pearson.csv\"))\n",
    "    \n",
    "#     # for easy access saving\n",
    "#     df.to_csv(os.path.join(\"results\", f\"{pair}_pearson.csv\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cRQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Erik\\\\Documents\\\\facial-expression-synchrony\\\\data-out\\\\07_08\\\\features\\\\pp07_discussion_phase_0_factors.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m nav = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mUsers\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mErik\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDocuments\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mfacial-expression-synchrony\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mdata-out\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m07_08\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mfeatures\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mpp07_discussion_phase_0_factors.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m pil = pd.read_csv(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mErik\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDocuments\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mfacial-expression-synchrony\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdata-out\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m07_08\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mfeatures\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mpp08_discussion_phase_0_factors.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m nav = nav.drop(columns=[\u001b[33m\"\u001b[39m\u001b[33mframe\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Erik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Erik\\\\Documents\\\\facial-expression-synchrony\\\\data-out\\\\07_08\\\\features\\\\pp07_discussion_phase_0_factors.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "nav = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\features\\pp07_discussion_phase_0_factors.csv\")\n",
    "pil = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\features\\pp08_discussion_phase_0_factors.csv\")\n",
    "nav = nav.drop(columns=[\"frame\"])\n",
    "pil = pil.drop(columns=[\"frame\"])\n",
    "nav = cm.binarize_components(nav.values)\n",
    "pil = cm.binarize_components(pil.values)\n",
    "\n",
    "cm.crqa2(\"bin_factors\",nav, pil)\n",
    "\n",
    "nav = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\features\\pp07_discussion_phase_0_corrca.csv\")\n",
    "pil = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\features\\pp08_discussion_phase_0_corrca.csv\")\n",
    "nav = nav.drop(columns=[\"frame\"])\n",
    "pil = pil.drop(columns=[\"frame\"])\n",
    "nav = cm.binarize_components(nav.values)\n",
    "pil = cm.binarize_components(pil.values)\n",
    "\n",
    "cm.crqa2(\"bin_corrca\",nav, pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nav = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp07_discussion_phase_0_factors.csv\")\n",
    "# pil = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp08_discussion_phase_0_factors.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# for f in factors:\n",
    "#     cm.crqa(f, nav[f].values, pil[f].values) \n",
    "\n",
    "\n",
    "# nav = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp07_discussion_phase_0_factors.csv\")\n",
    "# pil = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp08_discussion_phase_0_factors.csv\")\n",
    "\n",
    "# cm.crqa3(nav.iloc[1:].values, pil.iloc[1:].values)\n",
    "\n",
    "\n",
    "# nav = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp07_discussion_phase_0_factors.csv\")\n",
    "# pil = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp08_discussion_phase_0_factors.csv\")\n",
    "\n",
    "# cm.mimicry(nav.iloc[1:].values, pil.iloc[1:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recurrence rate: 0.3497\n",
      "Determinism: 0.7576\n",
      "Laminarity: 0.3193\n",
      "Average diagonal line length: 3.0239\n",
      "Longest diagonal line length: 353\n",
      "Recurrence rate: 0.5056\n",
      "Determinism: 0.5643\n",
      "Laminarity: 0.7805\n",
      "Average diagonal line length: 72.5376\n",
      "Longest diagonal line length: 1028\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import util.correlation_measure as cm\n",
    "nav = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp07_discussion_phase_0_factors.csv\")\n",
    "pil = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp08_discussion_phase_0_factors.csv\")\n",
    "nav = nav.drop(columns=[\"frame\"])\n",
    "pil = pil.drop(columns=[\"frame\"])\n",
    "nav = cm.binarize_components(nav.values)\n",
    "pil = cm.binarize_components(pil.values)\n",
    "\n",
    "cm.crqa2(\"bin_factors\",nav, pil)\n",
    "\n",
    "nav = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp07_discussion_phase_0_corrca.csv\")\n",
    "pil = pd.read_csv(r\"C:\\Users\\Erik\\Documents\\facial-expression-synchrony\\data-out\\07_08\\selection\\pp08_discussion_phase_0_corrca.csv\")\n",
    "nav = nav.drop(columns=[\"frame\"])\n",
    "pil = pil.drop(columns=[\"frame\"])\n",
    "nav = cm.binarize_components(nav.values)\n",
    "pil = cm.binarize_components(pil.values)\n",
    "\n",
    "cm.crqa2(\"bin_corrca\",nav, pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PHASES = [\"05_06\", \"07_08\", \"09_10\", \"11_12\", \"13_14\"]\n",
    "for p in PHASES:\n",
    "    df = pd.read_csv(f\"C:\\\\Users\\\\Erik\\\\Documents\\\\facial-expression-synchrony\\\\data-out\\\\{p}\\\\{p}_corrca_weights.csv\")\n",
    "    w = df['w']\n",
    "    isc = df['isc'].values  # Get values as a NumPy array\n",
    "\n",
    "    isc = [np.abs(i) for i in isc]  # Take absolute values\n",
    "    isc_sorted = sorted(isc, reverse=True)  # Sort in descending order (returns new list)\n",
    "\n",
    "    tot = np.sum(isc)\n",
    "    tmp = 0\n",
    "    for index, i in enumerate(isc):\n",
    "        tmp = tmp + i\n",
    "        if tmp/tot > 0.75:\n",
    "            print(index)\n",
    "            break\n",
    "\n",
    "    plt.plot(isc_sorted, label=p)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('ISC Value (Absolute)')\n",
    "plt.title('Reverse Sorted Absolute ISC Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "\n",
    "PHASES = [\"05_06\", \"07_08\", \"09_10\", \"11_12\", \"13_14\"]\n",
    "for p in PHASES:    \n",
    "    df = pd.read_csv(f\"C:\\\\Users\\\\Erik\\\\Documents\\\\facial-expression-synchrony\\\\data-out\\\\{p}\\\\{p}_corrca_weights.csv\")\n",
    "    isc = np.abs(df['isc'].values)  # Take absolute values and convert to NumPy array\n",
    "    isc_sorted = np.sort(isc)[::-1]  # Sort in descending order\n",
    "\n",
    "    # Compute cumulative contribution (optional)\n",
    "    cumulative_isc = np.cumsum(isc_sorted) / np.sum(isc_sorted)  # Normalized cumulative sum\n",
    "\n",
    "    # Create scree plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot individual ISC values (bars or line)\n",
    "    plt.plot(isc_sorted, 'b-', linewidth=2, label='Absolute ISC')\n",
    "    plt.scatter(range(len(isc_sorted)), isc_sorted, color='red', s=20)  # Optional: dots for each value\n",
    "\n",
    "    # Optional: Add cumulative contribution (dashed line)\n",
    "    plt.plot(cumulative_isc * max(isc_sorted), 'g--', linewidth=1, label='Cumulative (scaled)')\n",
    "\n",
    "    # Customize plot\n",
    "    plt.xlabel('Component Rank (Sorted Descending)', fontsize=12)\n",
    "    plt.ylabel('Absolute ISC Weight', fontsize=12)\n",
    "    plt.title('Scree Plot of ISC Weights', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general corrca\n",
    "data = {}\n",
    "nav, pil = pair.split(\"_\")\n",
    "nav_df = pd.DataFrame()\n",
    "pil_df = pd.DataFrame()\n",
    "\n",
    "for pair in os.listdir(LOCATION):\n",
    "    print(pair)\n",
    "    filename = os.path.join(LOCATION, pair)\n",
    "    for file in os.listdir(os.path.join(filename, \"au\")):\n",
    "        if \".csv\" in file: \n",
    "            df = pd.read_csv(os.path.join(filename, \"au\", file))\n",
    "            if \".csv\" in file and nav in file:\n",
    "                nav_df = pd.concat([nav_df, df])\n",
    "            if \".csv\" in file and pil in file:\n",
    "                pil_df = pd.concat([pil_df, df])\n",
    "nav_df, pil_df = fs.make_equal_length(pair, nav_df, pil_df)\n",
    "w = fs.corrCA_weights(nav_df, pil_df) #output = pair/pair_corrca_weights.csv\n",
    "w.to_csv(r\"data-out/general_corrca_weights.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files of pairs in 05_06 do not have the same amount of datapoints - temporary fix has made them equal length\n",
      "(17, 17)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import util.feature_extraction as fe\n",
    "import util.feature_selection as fs\n",
    "# corrCA takes a df as input. This df should be all files for a pair. \n",
    "LOCATION = 'data-out'\n",
    "\n",
    "pair = \"05_06\"\n",
    "filename = os.path.join(LOCATION, pair)\n",
    "data = {}\n",
    "nav, pil = pair.split(\"_\")\n",
    "nav_df = pd.DataFrame()\n",
    "pil_df = pd.DataFrame()\n",
    "# add all phases to a single dataframe\n",
    "for file in os.listdir(os.path.join(filename, \"au\")):\n",
    "    if \".csv\" in file: \n",
    "        df = pd.read_csv(os.path.join(filename, \"au\", file))\n",
    "        if \".csv\" in file and nav in file:\n",
    "            nav_df = pd.concat([nav_df, df])\n",
    "        if \".csv\" in file and pil in file:\n",
    "            pil_df = pd.concat([pil_df, df])\n",
    "nav_df, pil_df = fs.make_equal_length(pair, nav_df, pil_df)\n",
    "w = fs.corrCA_weights(nav_df, pil_df) #output = pair/pair_corrca_weights.csv\n",
    "w.to_csv(os.path.join(filename, f\"{pair}_corrca_weights.csv\"), index=False)\n",
    "\n",
    "LOCATION = 'data-out'\n",
    "PHASES = ['discussion_phase_0', 'discussion_phase_1', 'instructional_video_0']\n",
    "loc = os.path.join(LOCATION, pair, f'{pair}_corrca_weights.csv')\n",
    "w = pd.read_csv(os.path.join(LOCATION, pair, f'{pair}_corrca_weights.csv'))\n",
    "for file in os.listdir(os.path.join(LOCATION, pair, \"au\")):\n",
    "    if \".csv\" in file: \n",
    "        filename = os.path.join(LOCATION, pair, \"au\", file)\n",
    "        participant, _ = file.split(\"_\", 1)\n",
    "        df = pd.read_csv(filename)\n",
    "        for name in PHASES:\n",
    "            if name in file:\n",
    "                corrca = fs.apply_corrCA_weights(df, w, 3)\n",
    "                corrca.to_csv(os.path.join(LOCATION, pair, \"selection\", f\"{participant}_{name}_corrca.csv\"), index=False)\n",
    "                continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
